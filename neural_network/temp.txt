# CNN Training file

import os
import pandas as pd
import numpy
import torch.nn as NN
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, transforms
from torchvision.io import decode_image
from datetime import datetime
from torchvision.transforms import ToTensor
from torchvision.ops import box_iou
import torch
import torchvision
import torch.optim as optim

from DataLoading import *

## CNN for text detection

def collate_fn(batch):
     return tuple(zip(*batch))

class ConvolutionalNN(NN.Module):
     # CNN
     def __init__(self):
          super(ConvolutionalNN, self).__init__()
          self.convolutional_relu_seq = NN.Sequential(
               # 1
               NN.Conv2d(3, 25, 3, 1, padding=1),
               NN.BatchNorm2d(25),
               NN.ReLU(),
               NN.MaxPool2d(2,2),
               # 2
               NN.Conv2d(25, 75, 3, 1, padding=1), # 2D Convolutional Layer, Kernel Size 5, Moves 1 pixel (x,y) direction , 16 input layers to 24 output
               NN.BatchNorm2d(75),                 # Batches are standardized so feature learning to even
               NN.ReLU(),                          # Retified Learning Unit, Non-Linearity // Outlier detection or uniqueness 
               NN.MaxPool2d(2,2),                  # 4x4 grid of 2x2 pools, extracting highest # / highest feature
               # 3
               NN.Conv2d(75, 150, 3, 1, padding=1),
               NN.BatchNorm2d(150),
               NN.ReLU(), 
               NN.MaxPool2d(2,2)              
          )

          num_boxes = 1
          num_classes = 4
          self.box_head = NN.Conv2d(150, num_boxes*4, 1)
          self.class_head = NN.Conv2d(150, num_boxes*num_classes, 1)

     # Output Tensors, function used for training
     def forward(self, x):
          seq = self.convolutional_relu_seq(x)
          boxP = self.box_head(seq)
          classP = self.class_head(seq)

          # Single label, multi-class
          # boxP = boxP.mean(dim=[2,3])
          # classP = classP.mean(dim=[2,3])

          # Multi-label, multi-class
          n, _, h, w = boxP.shape
          boxP = boxP.permute(0,2,3,1).contiguous()
          boxP = boxP.view(n,-1,4)
          classP = classP.permute(0,2,3,1).contiguous()
          classP = classP.view(n,-1,4)

          return boxP, classP


## LOADING

# NOT EVERY image is the size resolution
resize = transforms.Compose([transforms.Resize((1000,750)), transforms.ToTensor()])
batch = 1

# Training loader
training_LOADER = DataLoader(
                              DocumentCSVDataset(
                              csv_file=datapata_training_csv, root_dir=datapath_training_image, transform=resize), 
                              batch_size=batch, shuffle=True, collate_fn=collate_fn)
testing_LOADER = DataLoader(
                              DocumentCSVDataset(
                              csv_file= datapata_testing_csv, root_dir=datapath_testing_image, transform=resize), 
                              batch_size=batch, shuffle=False, collate_fn=collate_fn)

print('Training set has {} instances'.format(len(training_LOADER)))
print('Testing set has {} instances'.format(len(testing_LOADER)))

# MODEL
model = ConvolutionalNN()
reg_lossfn = NN.SmoothL1Loss()
class_lossfn = NN.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr= 0.001)
device = torch.device("cuda")
model.to(device)

# TRAINING
train_losses = []
num_epochs = 10
for epoch in range(num_epochs):
     correction = 0
     for i, (image_name, image, boxes, labels) in enumerate(training_LOADER):
          # Handle image tuple from DataLoader
          if isinstance(image, (tuple, list)):
               image = image[0]
          if isinstance(boxes, (tuple, list)):
               boxes = boxes[0]
          if isinstance(labels, (tuple, list)):
               labels = labels[0]
     
          # Add dimension if missing
          if image.dim() == 3:
               image = image.unsqueeze(0)

          # Apply tensors to gpu
          image = image.to(device)
          boxes = boxes.to(device)
          labels = labels.to(device)

          # Forward function is called
          with torch.no_grad():
               dummy_boxes, dummy_obj, dummy_cls = model(image)
               H_out = dummy_boxes.shape[1]
               W_out = dummy_boxes.shape[2]

       
          gt_obj = torch.zeros((H_out, W_out), dtype=torch.float32, device=device)
          gt_boxes = torch.zeros((H_out, W_out, 4), dtype=torch.float32, device=device)
          gt_labels = torch.zeros((H_out, W_out), dtype=torch.long, device=device)

          for b in range(boxes.shape[0]):
               cx, cy, w, h = boxes[b]  # normalized
               clss = labels[b]

               # Find grid cell
               gx = int(cx * W_out)
               gy = int(cy * H_out)
               gx = max(0, min(W_out - 1, gx))
               gy = max(0, min(H_out - 1, gy))

               gt_obj[gy, gx] = 1.0

               # Convert to relative cell offsets
               cx_rel = cx * W_out - gx
               cy_rel = cy * H_out - gy
               w_rel = w
               h_rel = h

               gt_boxes[gy, gx] = torch.tensor([cx_rel, cy_rel, w_rel, h_rel], device=device)
               gt_labels[gy, gx] = clss
          pred_boxes, pred_obj, pred_classes = model(image)
          pred_boxes = pred_boxes.squeeze(0)
          pred_obj = pred_obj.squeeze(0)
          pred_classes = pred_classes.squeeze(0)

          # Objectness loss
          L_obj = NN.BCELoss(pred_obj, gt_obj.unsqueeze(-1))

          # Mask for object cells
          obj_mask = gt_obj == 1

          # SmoothL1 box regression ONLY for object cells
          L_box = NN.SmoothL1Loss(pred_boxes[obj_mask], gt_boxes[obj_mask])

          # Class loss only for object cells
          L_cls = NN.CrossEntropyLoss(pred_classes[obj_mask], gt_labels[obj_mask])

          # Total
          loss = L_obj + 5*L_box + L_cls

          optimizer.zero_grad()
          loss.backward()
          optimizer.step()

          #correction += (classP==labels).float().sum().item()
          #acc = correction/labels.size(0)
          
          if (i+1) % 10 == 9:
               print(f"[Epoch {epoch+1}, Batch {i+1}] Loss: {loss / 20:.12f}")

     train_losses.append(loss / len(training_LOADER))


# Save state
statepath = "../Document-Assistant/model_state/CNNstate.pt"
try:
     torch.save(model.state_dict(), statepath)
except:
     print("Cannot Open.")

# TRAINING

# Printing to see if everything is resized and every file is loaded, NOT printing boxes because it takes a while, add: boxes after shape if need be
# for i, (image_name, image, boxes, labels) in enumerate(training_LOADER):
#     print(i, image_name[0], image[0].shape)
"""
          boxP = boxP.squeeze(0)
          IoUP = torchvision.ops.box_iou(boxP, boxes)
          _, posBox = IoUP.max(dim=1)
          positiveMask = IoUP > .5
          target_classes = torch.ones_like(classP).to(device).float()

          # CrossEntropyLoss expects labels 
          loss = reg_lossfn(boxP, boxes[posBox]) + class_lossfn(classP, target_classes)
          
          # Changes weights within network
          loss.backward()
          optimizer.step()
"""


*****

# CNN Training file

import os
import pandas as pd
import numpy
import torch.nn as NN
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, transforms
from torchvision.io import decode_image
from datetime import datetime
from torchvision.transforms import ToTensor
from torchvision.ops import box_iou
import torch
import torchvision
import torch.optim as optim

from DataLoading import *

## CNN for text detection

def collate_fn(batch):
     return tuple(zip(*batch))

class ConvolutionalNN(NN.Module):
     # CNN
     def __init__(self):
          super(ConvolutionalNN, self).__init__()
          self.convolutional_relu_seq = NN.Sequential(
               # 1
               NN.Conv2d(3, 25, 3, 1, padding=1),
               NN.BatchNorm2d(25),
               NN.ReLU(),
               NN.MaxPool2d(2,2),
               # 2
               NN.Conv2d(25, 75, 3, 1, padding=1), # 2D Convolutional Layer, Kernel Size 5, Moves 1 pixel (x,y) direction , 16 input layers to 24 output
               NN.BatchNorm2d(75),                 # Batches are standardized so feature learning to even
               NN.ReLU(),                          # Retified Learning Unit, Non-Linearity // Outlier detection or uniqueness 
               NN.MaxPool2d(2,2),                  # 4x4 grid of 2x2 pools, extracting highest # / highest feature
               # 3
               NN.Conv2d(75, 150, 3, 1, padding=1),
               NN.BatchNorm2d(150),
               NN.ReLU(), 
               NN.MaxPool2d(2,2)              
          )

          num_boxes = 1
          num_classes = 4
          self.obj_head = NN.Conv2d(150, num_boxes*1, 1)
          self.box_head = NN.Conv2d(150, num_boxes*4, 1)
          self.class_head = NN.Conv2d(150, num_boxes*num_classes, 1)

     # Output Tensors, function used for training
     def forward(self, x):
          seq = self.convolutional_relu_seq(x)

          # Single label, multi-class
          # boxP = boxP.mean(dim=[2,3])
          # classP = classP.mean(dim=[2,3])

          # Multi-label, multi-class
          boxP = self.box_head(seq)               # (B,4,H,W)
          boxP = torch.sigmoid(boxP)               # constrain to 0..1
          boxP = boxP.permute(0,2,3,1)             # → (B,H,W,4)

          # Objectness
          objP = self.obj_head(seq)               # (B,1,H,W)
          objP = torch.sigmoid(objP)
          objP = objP.permute(0,2,3,1)             # → (B,H,W,1)

          # Class scores (raw logits)
          classP = self.class_head(seq)           # (B,4,H,W)
          classP = classP.permute(0,2,3,1)         # → (B,H,W,4)

          return boxP, objP, classP


## LOADING

# NOT EVERY image is the size resolution
resize = transforms.Compose([transforms.Resize((1000,750)), transforms.ToTensor()])
batch = 4

# Training loader
training_LOADER = DataLoader(
                              DocumentCSVDataset(
                              csv_file=datapata_training_csv, root_dir=datapath_training_image, transform=resize), 
                              batch_size=batch, shuffle=True, collate_fn=collate_fn)
testing_LOADER = DataLoader(
                              DocumentCSVDataset(
                              csv_file= datapata_testing_csv, root_dir=datapath_testing_image, transform=resize), 
                              batch_size=batch, shuffle=False, collate_fn=collate_fn)

print('Training set has {} instances'.format(len(training_LOADER)))
print('Testing set has {} instances'.format(len(testing_LOADER)))

# MODEL
model = ConvolutionalNN()
reg_lossfn = NN.SmoothL1Loss()
class_lossfn = NN.CrossEntropyLoss()
bce = NN.BCELoss()
SmoothL1 = NN.SmoothL1Loss()
ce = NN.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr= 0.001)
device = torch.device("cuda")
model.to(device)

# TRAINING
train_losses = []
num_epochs = 10
for epoch in range(num_epochs):
     correction = 0
     for i, (image_name, image, boxes, labels) in enumerate(training_LOADER):
          # Handle image tuple from DataLoader
          if isinstance(image, (tuple, list)):
               image = image[0]
          if isinstance(boxes, (tuple, list)):
               boxes = boxes[0]
          if isinstance(labels, (tuple, list)):
               labels = labels[0]
     
          # Add dimension if missing
          if image.dim() == 3:
               image = image.unsqueeze(0)

          # Apply tensors to gpu
          image = image.to(device)
          boxes = boxes.to(device)
          labels = labels.to(device)

          # Forward function is called
          with torch.no_grad():
               dummy_boxes, dummy_obj, dummy_cls = model(image)
               H_out = dummy_boxes.shape[1]
               W_out = dummy_boxes.shape[2]

       
          gt_obj = torch.zeros((H_out, W_out), dtype=torch.float32, device=device)
          gt_boxes = torch.zeros((H_out, W_out, 4), dtype=torch.float32, device=device)
          gt_labels = torch.zeros((H_out, W_out), dtype=torch.long, device=device)

          for b in range(boxes.shape[0]):
               cx, cy, w, h = boxes[b]  # normalized
               clss = labels[b]

               # Find grid cell
               gx = int(cx * W_out)
               gy = int(cy * H_out)
               gx = max(0, min(W_out - 1, gx))
               gy = max(0, min(H_out - 1, gy))

               gt_obj[gy, gx] = 1.0

               # Convert to relative cell offsets
               cx_rel = cx * W_out - gx
               cy_rel = cy * H_out - gy
               w_rel = w
               h_rel = h

               gt_boxes[gy, gx] = torch.tensor([cx_rel, cy_rel, w_rel, h_rel], device=device)
               gt_labels[gy, gx] = clss
          pred_boxes, pred_obj, pred_classes = model(image)
          pred_boxes = pred_boxes.squeeze(0)
          pred_obj = pred_obj.squeeze(0)
          pred_classes = pred_classes.squeeze(0)

          # Objectness loss
          L_obj = bce(pred_obj, gt_obj.unsqueeze(-1))

          # Mask for object cells
          obj_mask = gt_obj == 1

          # SmoothL1 box regression ONLY for object cells
          L_box = SmoothL1(pred_boxes[obj_mask], gt_boxes[obj_mask])

          # Class loss only for object cells
          L_cls = ce(pred_classes[obj_mask], gt_labels[obj_mask])

          # Total
          loss = L_obj + 5*L_box + L_cls

          optimizer.zero_grad()
          loss.backward()
          optimizer.step()

          #correction += (classP==labels).float().sum().item()
          #acc = correction/labels.size(0)
          
          if (i+1) % 10 == 9:
               print(f"[Epoch {epoch+1}, Batch {i+1}] Loss: {loss / 20:.12f}")

     train_losses.append(loss / len(training_LOADER))


# Save state
statepath = "../Document-Assistant/model_state/CNNstate.pt"
try:
     torch.save(model.state_dict(), statepath)
except:
     print("Cannot Open.")

# TRAINING

# Printing to see if everything is resized and every file is loaded, NOT printing boxes because it takes a while, add: boxes after shape if need be
# for i, (image_name, image, boxes, labels) in enumerate(training_LOADER):
#     print(i, image_name[0], image[0].shape)
"""
          boxP = boxP.squeeze(0)
          IoUP = torchvision.ops.box_iou(boxP, boxes)
          _, posBox = IoUP.max(dim=1)
          positiveMask = IoUP > .5
          target_classes = torch.ones_like(classP).to(device).float()

          # CrossEntropyLoss expects labels 
          loss = reg_lossfn(boxP, boxes[posBox]) + class_lossfn(classP, target_classes)
          
          # Changes weights within network
          loss.backward()
          optimizer.step()
"""